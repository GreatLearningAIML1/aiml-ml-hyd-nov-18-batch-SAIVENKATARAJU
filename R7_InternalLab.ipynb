{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FiX3MV-JYizg",
    "outputId": "0394307a-4016-4f86-f1f7-81dfdf62089a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import tensorflow as tf\n",
    "from keras.layers import Convolution2D,MaxPooling2D\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Qr75v_UYJjvs",
    "outputId": "00790922-d915-45d0-b97c-b5bc667fe7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g2sf67VoJjvx",
    "outputId": "576b7a80-d65c-48e5-af41-ff311601dfbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples are 60000 60000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"total samples are\",x_train.shape[0], y_train.shape[0], x_test.shape[0],y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zewyDcBlJjv1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XycQGBSGJjv5",
    "outputId": "86d757dd-4944-4b71-f7f1-ac1d11b03071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "y_train=tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mgHSCXy3JjwA",
    "outputId": "5dbaefdb-9d89-4541-e41c-681a2e2b4941"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fUQpMHxJjwE"
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okwo_SB5JjwI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPGVQ-JJJjwN"
   },
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,28,28,1)\n",
    "x_test=x_test.reshape(10000,28,28,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VXdJ6CZWhMQm",
    "outputId": "9d6e2a84-13f4-41cc-e332-9dac86a3dbdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D,MaxPooling2D,Activation,Flatten,Dense,Dropout\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "DORCLgSwJjwV",
    "outputId": "0541ccbc-e240-48a0-e494-67904bf14eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.3738 - acc: 0.8655 - val_loss: 0.2940 - val_acc: 0.8947\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2284 - acc: 0.9159 - val_loss: 0.2555 - val_acc: 0.9065\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.1619 - acc: 0.9391 - val_loss: 0.2576 - val_acc: 0.9129\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1090 - acc: 0.9596 - val_loss: 0.2885 - val_acc: 0.9109\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0746 - acc: 0.9722 - val_loss: 0.3357 - val_acc: 0.9082\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0486 - acc: 0.9824 - val_loss: 0.3430 - val_acc: 0.9131\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0346 - acc: 0.9875 - val_loss: 0.3849 - val_acc: 0.9160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c44ab22b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# First conv layer\n",
    "model.add(Convolution2D(32,3,3,input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "#second conv layer\n",
    "model.add(Convolution2D(32,3,3,))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "early_stops=keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "call_backs=[early_stops]\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=32,nb_epoch=10,validation_data=(x_test, y_test), callbacks=call_backs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "L2hAP94vJjwY",
    "outputId": "6507e11a-40b6-4e0a-e559-ee91f4dee69a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.3897 - acc: 0.8591 - val_loss: 0.3061 - val_acc: 0.8863\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.2585 - acc: 0.9047 - val_loss: 0.2579 - val_acc: 0.9058\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.2136 - acc: 0.9209 - val_loss: 0.2391 - val_acc: 0.9125\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1763 - acc: 0.9340 - val_loss: 0.2314 - val_acc: 0.9173\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1511 - acc: 0.9432 - val_loss: 0.2221 - val_acc: 0.9198\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1284 - acc: 0.9515 - val_loss: 0.2591 - val_acc: 0.9109\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1092 - acc: 0.9586 - val_loss: 0.2544 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0931 - acc: 0.9651 - val_loss: 0.2558 - val_acc: 0.9225\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0806 - acc: 0.9701 - val_loss: 0.2809 - val_acc: 0.9226\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0721 - acc: 0.9725 - val_loss: 0.2890 - val_acc: 0.9244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c382fa2b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "# First conv layer\n",
    "model2.add(Convolution2D(32,3,3,input_shape=(28,28,1)))\n",
    "model2.add(Activation('relu'))\n",
    "#second conv layer\n",
    "model2.add(Convolution2D(32,3,3,))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "# Dropout\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "#fully connected layer\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "early_stops=keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "call_backs=[early_stops]\n",
    "\n",
    "model2.fit(x_train,y_train,batch_size=32,nb_epoch=10,validation_data=(x_test, y_test), callbacks=call_backs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTA3bfEJjwa"
   },
   "source": [
    "### Now, to the above model, lets add Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6gX8n5SJjwb"
   },
   "source": [
    "### Import the ImageDataGenrator from keras and fit the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbz4uHBuJjwc"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl-8dOo7Jjwf"
   },
   "source": [
    "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "DpI1_McYJjwg",
    "outputId": "fc3e6584-1005-48e8-d8df-ca912f0e9b14",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+SJPkiRpOPkiT5IkaTj/BwWDp4P7nnIPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmPl5yE8Jjwm"
   },
   "source": [
    "### Run the above model using fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "44ZnDdJYJjwn",
    "outputId": "52979ecf-8059-4b24-d829-a9eb9acec98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  18/1875 [..............................] - ETA: 18s - loss: 0.4533 - acc: 0.8351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4785 - acc: 0.8218 - val_loss: 0.3153 - val_acc: 0.8893\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4534 - acc: 0.8319 - val_loss: 0.3247 - val_acc: 0.8876\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4271 - acc: 0.8432 - val_loss: 0.3097 - val_acc: 0.8937\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4137 - acc: 0.8461 - val_loss: 0.3325 - val_acc: 0.8852\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3979 - acc: 0.8532 - val_loss: 0.3247 - val_acc: 0.8888\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3907 - acc: 0.8567 - val_loss: 0.3081 - val_acc: 0.8898\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3808 - acc: 0.8595 - val_loss: 0.2893 - val_acc: 0.8991\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3720 - acc: 0.8621 - val_loss: 0.2980 - val_acc: 0.8935\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3662 - acc: 0.8645 - val_loss: 0.2912 - val_acc: 0.8948\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3607 - acc: 0.8670 - val_loss: 0.2961 - val_acc: 0.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c30283048>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(datagen.flow(x_train,y_train,batch_size=32),samples_per_epoch=x_train.shape[0],nb_epoch=10,validation_data=(x_test, y_test),callbacks=call_backs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwQQW5iOJjwq"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "`# This is formatted as code`\n",
    "```\n",
    "\n",
    "###  Report the final train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c1SrtBEPJjwq",
    "outputId": "847df3fe-9da0-49d6-91ce-0b0b8de42021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 53us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29606577682495117, 0.8967]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBwVWNQC2qZD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
