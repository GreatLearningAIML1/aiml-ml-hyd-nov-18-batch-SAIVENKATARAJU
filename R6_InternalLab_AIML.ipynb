{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnSsH8sNOB6F",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Reset Default graph - Needed only for Jupyter notebook\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.normalization import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4yQKMiJOB6R"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8pWsNQOB6X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "data=data.drop(columns=['date','symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlwbUgTwOB6i",
    "outputId": "56bad82a-f271-415a-e0d6-cbe1c4290743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hG9rGBOB6s"
   },
   "outputs": [],
   "source": [
    "data_1000=data.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature=data_1000.drop(columns=['close'])\n",
    "Target=data_1000['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(Feature,Target,test_size=0.20,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the graph in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xK0zBd1VOB64",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define input data placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDrYlWTuOB66"
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder(shape=[None,4],dtype=tf.float32,name='Xinput')\n",
    "x_n=tf.nn.l2_normalize(x,1)\n",
    "y_=tf.placeholder(shape=[None],dtype=tf.float32,name='Yinput')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L205qPeQOB7B"
   },
   "outputs": [],
   "source": [
    "W=tf.Variable(tf.zeros(shape=[4,1],name='Weights'))\n",
    "B=tf.Variable(tf.zeros(shape=[1],name='Bais'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "y=tf.add(tf.matmul(x_n,W),B,name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.square(y-y_),name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [],
   "source": [
    "train_op=tf.train.GradientDescentOptimizer(0.03).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execute the Graph for 100 epochs and observe the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvgj7eQOB7f"
   },
   "outputs": [],
   "source": [
    "epochs=100\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9smwOW-1OB7k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epochs  0 is-- 8301.9\n",
      "Loss for epochs  1 is-- 7286.18\n",
      "Loss for epochs  2 is-- 6499.6064\n",
      "Loss for epochs  3 is-- 5890.482\n",
      "Loss for epochs  4 is-- 5418.7783\n",
      "Loss for epochs  5 is-- 5053.4897\n",
      "Loss for epochs  6 is-- 4770.613\n",
      "Loss for epochs  7 is-- 4551.5522\n",
      "Loss for epochs  8 is-- 4381.9097\n",
      "Loss for epochs  9 is-- 4250.539\n",
      "Loss for epochs  10 is-- 4148.8057\n",
      "Loss for epochs  11 is-- 4070.024\n",
      "Loss for epochs  12 is-- 4009.0144\n",
      "Loss for epochs  13 is-- 3961.7695\n",
      "Loss for epochs  14 is-- 3925.184\n",
      "Loss for epochs  15 is-- 3896.8496\n",
      "Loss for epochs  16 is-- 3874.908\n",
      "Loss for epochs  17 is-- 3857.9175\n",
      "Loss for epochs  18 is-- 3844.7607\n",
      "Loss for epochs  19 is-- 3834.5703\n",
      "Loss for epochs  20 is-- 3826.68\n",
      "Loss for epochs  21 is-- 3820.5688\n",
      "Loss for epochs  22 is-- 3815.8376\n",
      "Loss for epochs  23 is-- 3812.1736\n",
      "Loss for epochs  24 is-- 3809.3345\n",
      "Loss for epochs  25 is-- 3807.1377\n",
      "Loss for epochs  26 is-- 3805.4353\n",
      "Loss for epochs  27 is-- 3804.1184\n",
      "Loss for epochs  28 is-- 3803.099\n",
      "Loss for epochs  29 is-- 3802.3088\n",
      "Loss for epochs  30 is-- 3801.6943\n",
      "Loss for epochs  31 is-- 3801.2207\n",
      "Loss for epochs  32 is-- 3800.8545\n",
      "Loss for epochs  33 is-- 3800.5696\n",
      "Loss for epochs  34 is-- 3800.3496\n",
      "Loss for epochs  35 is-- 3800.18\n",
      "Loss for epochs  36 is-- 3800.047\n",
      "Loss for epochs  37 is-- 3799.9448\n",
      "Loss for epochs  38 is-- 3799.8667\n",
      "Loss for epochs  39 is-- 3799.804\n",
      "Loss for epochs  40 is-- 3799.7583\n",
      "Loss for epochs  41 is-- 3799.7207\n",
      "Loss for epochs  42 is-- 3799.692\n",
      "Loss for epochs  43 is-- 3799.6697\n",
      "Loss for epochs  44 is-- 3799.6528\n",
      "Loss for epochs  45 is-- 3799.6409\n",
      "Loss for epochs  46 is-- 3799.6304\n",
      "Loss for epochs  47 is-- 3799.6233\n",
      "Loss for epochs  48 is-- 3799.616\n",
      "Loss for epochs  49 is-- 3799.6104\n",
      "Loss for epochs  50 is-- 3799.6072\n",
      "Loss for epochs  51 is-- 3799.6023\n",
      "Loss for epochs  52 is-- 3799.6023\n",
      "Loss for epochs  53 is-- 3799.6\n",
      "Loss for epochs  54 is-- 3799.5984\n",
      "Loss for epochs  55 is-- 3799.5967\n",
      "Loss for epochs  56 is-- 3799.5972\n",
      "Loss for epochs  57 is-- 3799.5964\n",
      "Loss for epochs  58 is-- 3799.5957\n",
      "Loss for epochs  59 is-- 3799.596\n",
      "Loss for epochs  60 is-- 3799.5952\n",
      "Loss for epochs  61 is-- 3799.5945\n",
      "Loss for epochs  62 is-- 3799.5945\n",
      "Loss for epochs  63 is-- 3799.5945\n",
      "Loss for epochs  64 is-- 3799.5945\n",
      "Loss for epochs  65 is-- 3799.5947\n",
      "Loss for epochs  66 is-- 3799.5935\n",
      "Loss for epochs  67 is-- 3799.5952\n",
      "Loss for epochs  68 is-- 3799.5952\n",
      "Loss for epochs  69 is-- 3799.5952\n",
      "Loss for epochs  70 is-- 3799.5952\n",
      "Loss for epochs  71 is-- 3799.5947\n",
      "Loss for epochs  72 is-- 3799.5945\n",
      "Loss for epochs  73 is-- 3799.5945\n",
      "Loss for epochs  74 is-- 3799.594\n",
      "Loss for epochs  75 is-- 3799.5947\n",
      "Loss for epochs  76 is-- 3799.5945\n",
      "Loss for epochs  77 is-- 3799.5935\n",
      "Loss for epochs  78 is-- 3799.594\n",
      "Loss for epochs  79 is-- 3799.5952\n",
      "Loss for epochs  80 is-- 3799.5945\n",
      "Loss for epochs  81 is-- 3799.5945\n",
      "Loss for epochs  82 is-- 3799.5945\n",
      "Loss for epochs  83 is-- 3799.5947\n",
      "Loss for epochs  84 is-- 3799.5945\n",
      "Loss for epochs  85 is-- 3799.5935\n",
      "Loss for epochs  86 is-- 3799.5945\n",
      "Loss for epochs  87 is-- 3799.5935\n",
      "Loss for epochs  88 is-- 3799.5935\n",
      "Loss for epochs  89 is-- 3799.5928\n",
      "Loss for epochs  90 is-- 3799.5935\n",
      "Loss for epochs  91 is-- 3799.5935\n",
      "Loss for epochs  92 is-- 3799.5935\n",
      "Loss for epochs  93 is-- 3799.5945\n",
      "Loss for epochs  94 is-- 3799.5945\n",
      "Loss for epochs  95 is-- 3799.5945\n",
      "Loss for epochs  96 is-- 3799.5945\n",
      "Loss for epochs  97 is-- 3799.5945\n",
      "Loss for epochs  98 is-- 3799.5945\n",
      "Loss for epochs  99 is-- 3799.5945\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    _,train_loss=sess.run([train_op,loss],feed_dict={x:Xtrain,y_:Ytrain})\n",
    "    \n",
    "    print(\"Loss for epochs \",epoch, \"is--\",train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JuLI6bSOB7n"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    _,train_loss=sess.run([train_op,loss],feed_dict={x:Xtrain,y_:Ytrain})\n",
    "    \n",
    "    print(\"Loss for epochs \",epoch, \"is--\",train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b\n",
    "\n",
    "Hint: Use sess.run(W) to get W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGvtyTeuOB7r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6130278e-03],\n",
       "       [2.5889862e-03],\n",
       "       [2.6335130e-03],\n",
       "       [3.3549519e+01]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhDtOv5UOB7x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(W).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZqKUEFsOB71"
   },
   "source": [
    "### Find the Absolute mean square loss difference between training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97t-grQgOB71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epochs  0 is-- 1814.783\n",
      "Loss for epochs  1 is-- 1814.1952\n",
      "Loss for epochs  2 is-- 1813.738\n",
      "Loss for epochs  3 is-- 1813.3848\n",
      "Loss for epochs  4 is-- 1813.1116\n",
      "Loss for epochs  5 is-- 1812.9008\n",
      "Loss for epochs  6 is-- 1812.7375\n",
      "Loss for epochs  7 is-- 1812.6104\n",
      "Loss for epochs  8 is-- 1812.5116\n",
      "Loss for epochs  9 is-- 1812.4348\n",
      "Loss for epochs  10 is-- 1812.376\n",
      "Loss for epochs  11 is-- 1812.3314\n",
      "Loss for epochs  12 is-- 1812.2957\n",
      "Loss for epochs  13 is-- 1812.2676\n",
      "Loss for epochs  14 is-- 1812.2468\n",
      "Loss for epochs  15 is-- 1812.2308\n",
      "Loss for epochs  16 is-- 1812.2172\n",
      "Loss for epochs  17 is-- 1812.2084\n",
      "Loss for epochs  18 is-- 1812.2004\n",
      "Loss for epochs  19 is-- 1812.1945\n",
      "Loss for epochs  20 is-- 1812.19\n",
      "Loss for epochs  21 is-- 1812.1858\n",
      "Loss for epochs  22 is-- 1812.184\n",
      "Loss for epochs  23 is-- 1812.1808\n",
      "Loss for epochs  24 is-- 1812.1808\n",
      "Loss for epochs  25 is-- 1812.1788\n",
      "Loss for epochs  26 is-- 1812.178\n",
      "Loss for epochs  27 is-- 1812.1766\n",
      "Loss for epochs  28 is-- 1812.1757\n",
      "Loss for epochs  29 is-- 1812.176\n",
      "Loss for epochs  30 is-- 1812.1761\n",
      "Loss for epochs  31 is-- 1812.1757\n",
      "Loss for epochs  32 is-- 1812.1752\n",
      "Loss for epochs  33 is-- 1812.1752\n",
      "Loss for epochs  34 is-- 1812.1732\n",
      "Loss for epochs  35 is-- 1812.1757\n",
      "Loss for epochs  36 is-- 1812.1748\n",
      "Loss for epochs  37 is-- 1812.1744\n",
      "Loss for epochs  38 is-- 1812.1746\n",
      "Loss for epochs  39 is-- 1812.1732\n",
      "Loss for epochs  40 is-- 1812.1748\n",
      "Loss for epochs  41 is-- 1812.174\n",
      "Loss for epochs  42 is-- 1812.1744\n",
      "Loss for epochs  43 is-- 1812.1752\n",
      "Loss for epochs  44 is-- 1812.1752\n",
      "Loss for epochs  45 is-- 1812.1724\n",
      "Loss for epochs  46 is-- 1812.1744\n",
      "Loss for epochs  47 is-- 1812.1748\n",
      "Loss for epochs  48 is-- 1812.174\n",
      "Loss for epochs  49 is-- 1812.1744\n",
      "Loss for epochs  50 is-- 1812.1746\n",
      "Loss for epochs  51 is-- 1812.1736\n",
      "Loss for epochs  52 is-- 1812.174\n",
      "Loss for epochs  53 is-- 1812.1748\n",
      "Loss for epochs  54 is-- 1812.1736\n",
      "Loss for epochs  55 is-- 1812.1744\n",
      "Loss for epochs  56 is-- 1812.1744\n",
      "Loss for epochs  57 is-- 1812.173\n",
      "Loss for epochs  58 is-- 1812.1736\n",
      "Loss for epochs  59 is-- 1812.1736\n",
      "Loss for epochs  60 is-- 1812.1748\n",
      "Loss for epochs  61 is-- 1812.1744\n",
      "Loss for epochs  62 is-- 1812.1744\n",
      "Loss for epochs  63 is-- 1812.1748\n",
      "Loss for epochs  64 is-- 1812.1752\n",
      "Loss for epochs  65 is-- 1812.1752\n",
      "Loss for epochs  66 is-- 1812.1748\n",
      "Loss for epochs  67 is-- 1812.1744\n",
      "Loss for epochs  68 is-- 1812.1744\n",
      "Loss for epochs  69 is-- 1812.1744\n",
      "Loss for epochs  70 is-- 1812.1748\n",
      "Loss for epochs  71 is-- 1812.1752\n",
      "Loss for epochs  72 is-- 1812.1748\n",
      "Loss for epochs  73 is-- 1812.1744\n",
      "Loss for epochs  74 is-- 1812.1744\n",
      "Loss for epochs  75 is-- 1812.1744\n",
      "Loss for epochs  76 is-- 1812.1744\n",
      "Loss for epochs  77 is-- 1812.1744\n",
      "Loss for epochs  78 is-- 1812.1744\n",
      "Loss for epochs  79 is-- 1812.174\n",
      "Loss for epochs  80 is-- 1812.1744\n",
      "Loss for epochs  81 is-- 1812.1744\n",
      "Loss for epochs  82 is-- 1812.1744\n",
      "Loss for epochs  83 is-- 1812.174\n",
      "Loss for epochs  84 is-- 1812.174\n",
      "Loss for epochs  85 is-- 1812.174\n",
      "Loss for epochs  86 is-- 1812.174\n",
      "Loss for epochs  87 is-- 1812.174\n",
      "Loss for epochs  88 is-- 1812.174\n",
      "Loss for epochs  89 is-- 1812.174\n",
      "Loss for epochs  90 is-- 1812.174\n",
      "Loss for epochs  91 is-- 1812.174\n",
      "Loss for epochs  92 is-- 1812.174\n",
      "Loss for epochs  93 is-- 1812.174\n",
      "Loss for epochs  94 is-- 1812.174\n",
      "Loss for epochs  95 is-- 1812.174\n",
      "Loss for epochs  96 is-- 1812.174\n",
      "Loss for epochs  97 is-- 1812.174\n",
      "Loss for epochs  98 is-- 1812.174\n",
      "Loss for epochs  99 is-- 1812.174\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    _,test_loss=sess.run([train_op,loss],feed_dict={x:Xtest,y_:Ytest})\n",
    "    \n",
    "    print(\"Loss for epochs \",epoch, \"is--\",test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjOInjUROB75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987.4205"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(train_loss-test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZUAjZ5oOB78"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "### Linear Classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GoNTWXAOB8C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
    "#### Use Mean square error as loss function and sgd as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpeL5rCTOB8D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, input_dim=4, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,input_dim=4,init='uniform',activation='softmax'))\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt-HYFMEOB8G",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66JGJt7GOB8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 146us/step - loss: 7729.0366\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 131us/step - loss: 7729.0365\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 7729.0364\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 138us/step - loss: 7729.0365\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 139us/step - loss: 7729.0365\n",
      "1000/1000 [==============================] - 0s 27us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(Feature.values,Target.values,batch_size=10,epochs=5)\n",
    "scores=model.evaluate(Feature,Target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature=iris.drop(columns=['Species','Id'])\n",
    "Target=iris['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target=pd.get_dummies(Target,columns='Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_2,Xtest_2,Ytrain_2,Ytest_2=train_test_split(Feature,Target,test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Build the model with following layers: <br>\n",
    "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
    "2. Second Dense layer with 8 neurons <br>\n",
    "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
    "4. Use SGD and categorical_crossentropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, input_dim=4, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10,input_dim=4,init='uniform'))\n",
    "model.add(Dense(8,))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model and predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.3163 - acc: 0.8571\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.2823 - acc: 0.9048\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.4128 - acc: 0.7905\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.3844 - acc: 0.8381\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.3644 - acc: 0.8381\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.3414 - acc: 0.8476\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.3687 - acc: 0.8476\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.3472 - acc: 0.8571\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.4730 - acc: 0.7810\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.3856 - acc: 0.8381\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.3020 - acc: 0.8571\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.3173 - acc: 0.8381\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.3005 - acc: 0.8857\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.3280 - acc: 0.8857\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.2815 - acc: 0.8857\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.2433 - acc: 0.9429\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.2850 - acc: 0.9048\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.3183 - acc: 0.8286\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.2453 - acc: 0.9048\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.2921 - acc: 0.8857\n",
      "45/45 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(Xtrain_2.values,Ytrain_2.values,batch_size=10,epochs=20)\n",
    "scores=model.evaluate(Xtest_2,Ytest_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Accuracy of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 86.66666719648573\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names[1],scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Linear+classification+using+Tensorflow+and+Keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
